{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4 Anastasia Zimina.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPozes7Tq08UHyBPrbq2C0x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anastaszi/255_datamining/blob/main/HW4_Anastasia_Zimina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG1pkdS-NdbN"
      },
      "source": [
        "# Approximate Nearest Neighbors\n",
        "* LSH\n",
        "* Exhaustive search\n",
        "* Product Quantization\n",
        "* Trees and Graphs\n",
        "* HNSW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qksUt_GSThNN"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gTeoXwPTpIN",
        "outputId": "9c4b5b42-e145-4c26-80fb-4af4773fd01c"
      },
      "source": [
        "!pip install datasketch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasketch in /usr/local/lib/python3.7/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from datasketch) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32kEbhn-TloY"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import datasketch\n",
        "from datasketch import MinHash, MinHashLSHForest"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXAtNFXS4onm",
        "outputId": "419b47b3-60c5-4b95-bb7c-d4603e42d387"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW8vY9ivN92O"
      },
      "source": [
        "# LSH\n",
        ">  LSH is a hashing based algorithm to identify approximate nearest neighbors. LSH generates a hash value for a data item embeddings while keeping spatiality of data in mind; in particular; data items that are similar in high-dimension will have a higher chance of receiving the same hash value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3DCEaRuGdJ5"
      },
      "source": [
        "Dataset: [Indian Food Receipts](https://www.kaggle.com/nehaprabhavalkar/indian-food-101)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnZoli3Q5IRT"
      },
      "source": [
        "Task: Recommendation Engine of Similar Dishes based on ingredients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzHg7C5ZGfPB"
      },
      "source": [
        "df_indian_food = pd.read_csv('/content/gdrive/MyDrive/DataMining/indian_food.csv')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "DIpAB_46Go6U",
        "outputId": "a6eb8653-2471-45c6-cdc9-ccdedd73b967"
      },
      "source": [
        "df_indian_food.head(1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>diet</th>\n",
              "      <th>prep_time</th>\n",
              "      <th>cook_time</th>\n",
              "      <th>flavor_profile</th>\n",
              "      <th>course</th>\n",
              "      <th>state</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Balu shahi</td>\n",
              "      <td>Maida flour, yogurt, oil, sugar</td>\n",
              "      <td>vegetarian</td>\n",
              "      <td>45</td>\n",
              "      <td>25</td>\n",
              "      <td>sweet</td>\n",
              "      <td>dessert</td>\n",
              "      <td>West Bengal</td>\n",
              "      <td>East</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         name                      ingredients  ...        state  region\n",
              "0  Balu shahi  Maida flour, yogurt, oil, sugar  ...  West Bengal    East\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zswKKkI7Q9e"
      },
      "source": [
        "## Shingles\n",
        "Convert the query text to shingles (tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho0CRX0DG35K"
      },
      "source": [
        "def preprocessIngredients(text):\n",
        "  text = text.lower()\n",
        "  tokens = text.split(', ')\n",
        "  tokens = list(filter(lambda x: len(x) > 0, tokens))\n",
        "  return tokens"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH7IyuvbIHfu",
        "outputId": "6b17a8f6-b1df-4751-fe28-c46ecad76219"
      },
      "source": [
        "preprocessIngredients('Maida flour, yogurt, oil, sugar')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['maida flour', 'yogurt', 'oil', 'sugar']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FTiWpkP7T5_"
      },
      "source": [
        "## MinHash and LSH\n",
        "Apply MinHash and LSH to the shingle set, which maps it to a specific bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sorUmxAC89-f"
      },
      "source": [
        "#Number of permutations\n",
        "permutations = 128#@param\n",
        "#Number of Recommendations to return\n",
        "num_recommendations = 5#@param"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NancfhDFZuy",
        "outputId": "69303570-6494-41d7-ad19-44c13ddcdac1"
      },
      "source": [
        "df_indian_food.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(255, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwKCFkfC-5ja"
      },
      "source": [
        "def create_forest(data, perms, label):\n",
        "    start_time = time.time()\n",
        "    minhash = []\n",
        "    for text in data[label]:\n",
        "        # process each item in the dataset and convert it to an array of shingles\n",
        "        tokens = preprocessIngredients(text)\n",
        "        # set number of permutations in MinHash\n",
        "        m = MinHash(num_perm=perms)\n",
        "        # MinHash the string, i.e add to MinHash each shingle in it\n",
        "        for s in tokens:\n",
        "            m.update(s.encode('utf8'))\n",
        "        # store MinHash of the string in the array\n",
        "        minhash.append(m)\n",
        "    # build a forest of all MinHash values computed during the previous step \n",
        "    forest = MinHashLSHForest(num_perm=perms)\n",
        "    # index the forest to make it searchable\n",
        "    for i,m in enumerate(minhash):\n",
        "        forest.add(i,m)  \n",
        "    forest.index()\n",
        "    print('It took %s seconds to build forest.' %(time.time()-start_time))\n",
        "    return forest"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "280kySDRAvw7",
        "outputId": "972d52d1-5092-4ba5-d574-da36803a3d4d"
      },
      "source": [
        "forest = create_forest(df_indian_food, permutations, 'ingredients')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 0.38170933723449707 seconds to build forest.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-VIzmrK7ZBp"
      },
      "source": [
        "## Similarity search\n",
        "Conduct a similarity search between the query item and the other items in the bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeT7gzx4BGTn"
      },
      "source": [
        "def get_recommendations(text, database, labels, perms, num_results, forest):\n",
        "    start_time = time.time()\n",
        "    # tokenize input text \n",
        "    tokens = preprocessIngredients(text)\n",
        "    m = MinHash(num_perm=perms)\n",
        "    for s in tokens:\n",
        "        m.update(s.encode('utf8')) \n",
        "    idx_array = np.array(forest.query(m, num_results))\n",
        "    if len(idx_array) == 0:\n",
        "        return None # if your query is empty, return none\n",
        "    result = database.loc[idx_array, labels]\n",
        "    print('It took %s seconds to query forest.' %(time.time()-start_time))\n",
        "    return result"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLnn3_vIBgJ-",
        "outputId": "a778f601-53f5-4870-feb0-459e1b28b4e3"
      },
      "source": [
        "ingredients = 'sugar, milk'\n",
        "result = get_recommendations(ingredients, df_indian_food, ['name', 'ingredients'], permutations, num_recommendations, forest)\n",
        "print('\\n Top Recommendation(s) is(are) \\n', result)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 0.008231878280639648 seconds to query forest.\n",
            "\n",
            " Top Recommendation(s) is(are) \n",
            "               name                  ingredients\n",
            "8         Kalakand  Milk, cottage cheese, sugar\n",
            "11           Lassi    Yogurt, milk, nuts, sugar\n",
            "43  Kakinada khaja           Wheat flour, sugar\n",
            "21   Chhena kheeri          Chhena, sugar, milk\n",
            "56         Basundi            Sugar, milk, nuts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtyZpn05KgIk"
      },
      "source": [
        "# Exhaustive search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjMBgPOX33Ot"
      },
      "source": [
        "Dataset: [Million Headlines](https://www.kaggle.com/therohk/million-headlines?select=abcnews-date-text.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNRiFimO4u62"
      },
      "source": [
        "data = pd.read_csv('/content/gdrive/MyDrive/DataMining/abcnews-date-text.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "PzHr1_5B4-gZ",
        "outputId": "f4fff360-b2ac-41a9-e531-ee649a5427a5"
      },
      "source": [
        "data.head(1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20030219</td>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   publish_date                                      headline_text\n",
              "0      20030219  aba decides against community broadcasting lic..."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIGbGtp67s4b"
      },
      "source": [
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    tokens = text.split(' ')\n",
        "    tokens = list(filter(lambda x: len(x) > 0, tokens))\n",
        "    return tokens"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhC5PwwM72SY",
        "outputId": "b6288851-79b6-4959-e248-2bf3feb56590"
      },
      "source": [
        "preprocess(' this IS a test string with  With extra whitespaces ')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'a', 'test', 'string', 'with', 'with', 'extra', 'whitespaces']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s0GkX1AS8PS"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaiSKgMlS-WE"
      },
      "source": [
        "* [Finding similar images using Deep learning and Locality Sensitive Hashing](https://towardsdatascience.com/finding-similar-images-using-deep-learning-and-locality-sensitive-hashing-9528afee02f5)\n",
        "* [Implementing LSH in Python](https://www.learndatasci.com/tutorials/building-recommendation-engine-locality-sensitive-hashing-lsh-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_B9Z9t_3Eve"
      },
      "source": [
        "https://colab.research.google.com/github/pinecone-io/examples/blob/master/deduplication/deduplication_scholarly_articles.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}